{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7oVbe_pLr3C"
   },
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftT-5-yynCtl"
   },
   "source": [
    "<a name=\"0\"></a>\n",
    "# Introduction\n",
    "\n",
    "We first start by defining named entity recognition (NER). NER is a subtask of information extraction that locates and classifies named entities in a text. The named entities could be organizations, persons, locations, times, etc.\n",
    "\n",
    "Everything else that is labeled with an `O` is not considered to be a named entity.\n",
    "In this notebook, you will train a named entity recognition system that could be trained in a few seconds (on a GPU) and will get around 75% accuracy. Then, you will load in the exact version of your model, which was trained for a longer period of time. You could then evaluate the trained version of your model to get 96% accuracy! Finally, you will be able to test your named entity recognition system with your own sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5387,
     "status": "ok",
     "timestamp": 1729243292229,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "lvDDRHzNh_Xt",
    "outputId": "f3fc22d4-04cf-4f10-aefc-67cca0813264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trax\n",
      "  Downloading trax-1.4.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trax) (1.4.0)\n",
      "Collecting funcsigs (from trax)\n",
      "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from trax) (0.5.0)\n",
      "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from trax) (0.25.2)\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from trax) (0.4.33)\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from trax) (0.4.33)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from trax) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trax) (1.26.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trax) (5.9.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from trax) (1.13.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trax) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from trax) (4.9.6)\n",
      "Collecting tensorflow-text (from trax)\n",
      "  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->trax) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->trax) (0.0.8)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->trax) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->trax) (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->trax) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->trax) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->trax) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->trax) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->trax) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->trax) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->trax) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->trax) (2.8.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (0.1.8)\n",
      "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (4.2.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (3.20.3)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (16.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (2.32.3)\n",
      "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (1.16.1)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (2.5.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (4.66.5)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (1.16.0)\n",
      "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->trax) (0.5.1)\n",
      "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->trax) (1.9.4)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->trax) (2.17.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->trax) (4.12.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->trax) (2024.6.1)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->trax) (6.4.5)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->trax) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2024.8.30)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (18.1.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (71.0.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (0.37.1)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->trax) (0.16)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (0.44.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (13.9.2)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (0.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (3.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17.0->tensorflow-text->trax) (0.1.2)\n",
      "Downloading trax-1.4.1-py2.py3-none-any.whl (637 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
      "Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: funcsigs, tensorflow-text, trax\n",
      "Successfully installed funcsigs-1.0.2 tensorflow-text-2.17.0 trax-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install trax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYMMfxEe98sY"
   },
   "source": [
    "Create a directory **colab_data** in your Google Drive.\n",
    "\n",
    "Copy the contents of the compressed file **Lab2_NER.rar** to this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96018,
     "status": "ok",
     "timestamp": 1729243442475,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "qTgEKy_h72oq",
    "outputId": "cd5fa173-7f3e-44d4-a7b6-97ef6739c217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1729243802221,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "HCT2AmXX9iqj"
   },
   "outputs": [],
   "source": [
    "# Add the path to 'utils.py' to your Python path\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/colab_data') # Replace with your actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1081,
     "status": "ok",
     "timestamp": 1729243805170,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "JEY_jlQQR9SP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import trax\n",
    "from trax import layers as tl\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import get_params, get_vocab\n",
    "import random as rnd\n",
    "\n",
    "# set random seeds\n",
    "rnd.seed(33)\n",
    "np.random.seed(33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PpjG5MuLr3F"
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "# Part 1:  Exploring the data\n",
    "\n",
    "We will be using a dataset from Kaggle. The original data consists of four columns, the sentence number, the word, the part of speech of the word, and the tags.  A few tags you might expect to see are:\n",
    "\n",
    "* geo: geographical entity\n",
    "* org: organization\n",
    "* per: person\n",
    "* gpe: geopolitical entity\n",
    "* tim: time indicator\n",
    "* art: artifact\n",
    "* eve: event\n",
    "* nat: natural phenomenon\n",
    "* O: filler word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1729243512792,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "-Jur1JnXnCtr",
    "outputId": "dd66f5ca-c384-4a61-e8b4-0c2d698e8877",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "\n",
      "SENTENCE LABEL: O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
      "\n",
      "ORIGINAL DATA:\n",
      "        Sentence_ID                                               Word  \\\n",
      "0      Sentence: 1  ['Thousands', 'of', 'demonstrators', 'have', '...   \n",
      "1     Sentence: 10  ['Iranian', 'officials', 'say', 'they', 'expec...   \n",
      "2    Sentence: 100  ['Helicopter', 'gunships', 'Saturday', 'pounde...   \n",
      "3   Sentence: 1000  ['They', 'left', 'after', 'a', 'tense', 'hour-...   \n",
      "4  Sentence: 10000  ['U.N.', 'relief', 'coordinator', 'Jan', 'Egel...   \n",
      "\n",
      "                                                 POS  \\\n",
      "0  ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n",
      "1  ['JJ', 'NNS', 'VBP', 'PRP', 'VBP', 'TO', 'VB',...   \n",
      "2  ['NN', 'NNS', 'NNP', 'VBD', 'JJ', 'NNS', 'IN',...   \n",
      "3  ['PRP', 'VBD', 'IN', 'DT', 'NN', 'JJ', 'NN', '...   \n",
      "4  ['NNP', 'NN', 'NN', 'NNP', 'NNP', 'VBD', 'NNP'...   \n",
      "\n",
      "                                                 Tag  \n",
      "0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n",
      "1  ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...  \n",
      "2  ['O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', '...  \n",
      "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
      "4  ['B-geo', 'O', 'O', 'B-per', 'I-per', 'O', 'B-...  \n"
     ]
    }
   ],
   "source": [
    "# display original kaggle data\n",
    "data = pd.read_csv(\"/content/drive/My Drive/colab_data/NER_Dataset.csv\", encoding = \"ISO-8859-1\")\n",
    "train_sents = open('/content/drive/My Drive/colab_data/data/small/train/sentences.txt', 'r').readline()\n",
    "train_labels = open('/content/drive/My Drive/colab_data/data/small/train/labels.txt', 'r').readline()\n",
    "print('SENTENCE:', train_sents)\n",
    "print('SENTENCE LABEL:', train_labels)\n",
    "print('ORIGINAL DATA:\\n', data.head(5))\n",
    "del(data, train_sents, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoH6yBWVfzTb"
   },
   "source": [
    "<a name=\"1.1\"></a>\n",
    "## 1.1  Importing the Data\n",
    "\n",
    "In this part, we will import the preprocessed data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 9788,
     "status": "ok",
     "timestamp": 1729244252098,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "UauHjIKHWC0N",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab, tag_map = get_vocab('/content/drive/My Drive/colab_data/data/large/words.txt', '/content/drive/My Drive/colab_data/data/large/tags.txt')\n",
    "t_sentences, t_labels, t_size = get_params(vocab, tag_map, '/content/drive/My Drive/colab_data/data/large/train/sentences.txt', '/content/drive/My Drive/colab_data/data/large/train/labels.txt')\n",
    "v_sentences, v_labels, v_size = get_params(vocab, tag_map, '/content/drive/My Drive/colab_data/data/large/val/sentences.txt', '/content/drive/My Drive/colab_data/data/large/val/labels.txt')\n",
    "test_sentences, test_labels, test_size = get_params(vocab, tag_map, '/content/drive/My Drive/colab_data/data/large/test/sentences.txt', '/content/drive/My Drive/colab_data/data/large/test/labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcQi6EmWnCty"
   },
   "source": [
    "`vocab` is a dictionary that translates a word string to a unique number. Given a sentence, you can represent it as an array of numbers translating with this dictionary. The dictionary contains a `<PAD>` token.\n",
    "\n",
    "When training an LSTM using batches, all your input sentences must be the same size. To accomplish this, you set the length of your sentences to a certain number and add the generic `<PAD>` token to fill all the empty spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1729244443482,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "sm2P8y7zNgdU",
    "outputId": "4701dcb5-1518-4612-919d-37236361b2f5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab[\"the\"]: 9\n",
      "padded token: 35180\n"
     ]
    }
   ],
   "source": [
    "# vocab translates from a word to a unique number\n",
    "print('vocab[\"the\"]:', vocab[\"the\"])\n",
    "# Pad token\n",
    "print('padded token:', vocab['<PAD>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY6BTBjunCt1"
   },
   "source": [
    "The tag_map corresponds to one of the possible tags a word can have. Run the cell below to see the possible classes you will be predicting. The prepositions in the tags mean:\n",
    "* I: Token is inside an entity.\n",
    "* B: Token begins an entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729244446803,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "ZzMamaPcQXWP",
    "outputId": "93ece69c-34fb-40b9-c9f4-68bcb925a56b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-geo': 1, 'B-gpe': 2, 'B-per': 3, 'I-geo': 4, 'B-org': 5, 'I-org': 6, 'B-tim': 7, 'B-art': 8, 'I-art': 9, 'I-per': 10, 'I-gpe': 11, 'I-tim': 12, 'B-nat': 13, 'B-eve': 14, 'I-eve': 15, 'I-nat': 16}\n"
     ]
    }
   ],
   "source": [
    "print(tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1729244449394,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "xM9B_Rwxd01i",
    "outputId": "d44fce1e-43f8-4c08-fd79-9203ced342ff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outputs is tag_map 17\n",
      "Num of vocabulary words: 35181\n",
      "The vocab size is 35181\n",
      "The training size is 33570\n",
      "The validation size is 7194\n"
     ]
    }
   ],
   "source": [
    "# Exploring information about the data\n",
    "print('The number of outputs is tag_map', len(tag_map))\n",
    "# The number of vocabulary tokens (including <PAD>)\n",
    "g_vocab_size = len(vocab)\n",
    "print(f\"Num of vocabulary words: {g_vocab_size}\")\n",
    "print('The vocab size is', len(vocab))\n",
    "print('The training size is', t_size)\n",
    "print('The validation size is', v_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPd5a-4_nCt8"
   },
   "source": [
    "So you can see that we have already encoded each sentence into a tensor by converting it into a number. We also have 16 possible classes, as shown in the tag map.\n",
    "\n",
    "\n",
    "<a name=\"1.2\"></a>\n",
    "## 1.2  Data generator\n",
    "\n",
    "In python, a generator is a function that behaves like an iterator. It will return the next item. Here is a [link](https://wiki.python.org/moin/Generators) to review python generators.\n",
    "\n",
    "In many AI applications it is very useful to have a data generator. We will now implement a data generator for our NER application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1729244458929,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "tP7zQC8knCt_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_generator(batch_size, x, y, pad, shuffle=False, verbose=False):\n",
    "    '''\n",
    "      Input:\n",
    "        batch_size - integer describing the batch size\n",
    "        x - list containing sentences where words are represented as integers\n",
    "        y - list containing tags associated with the sentences\n",
    "        shuffle - Shuffle the data order\n",
    "        pad - an integer representing a pad character\n",
    "        verbose - Print information during runtime\n",
    "      Output:\n",
    "        a tuple containing 2 elements:\n",
    "        X - np.ndarray of dim (batch_size, max_len) of padded sentences\n",
    "        Y - np.ndarray of dim (batch_size, max_len) of tags associated with the sentences in X\n",
    "    '''\n",
    "\n",
    "    # count the number of lines in data_lines\n",
    "    num_lines = len(x)\n",
    "\n",
    "    # create an array with the indexes of data_lines that can be shuffled\n",
    "    lines_index = [*range(num_lines)]\n",
    "\n",
    "    # shuffle the indexes if shuffle is set to True\n",
    "    if shuffle:\n",
    "        rnd.shuffle(lines_index)\n",
    "\n",
    "    index = 0 # tracks current location in x, y\n",
    "    while True:\n",
    "        buffer_x = [0] * batch_size # Temporal array to store the raw x data for this batch\n",
    "        buffer_y = [0] * batch_size # Temporal array to store the raw y data for this batch\n",
    "\n",
    "        max_len = 0\n",
    "        for i in range(batch_size):\n",
    "             # if the index is greater than or equal to the number of lines in x\n",
    "            if index >= num_lines:\n",
    "                # then reset the index to 0\n",
    "                index = 0\n",
    "                # re-shuffle the indexes if shuffle is set to True\n",
    "                if shuffle:\n",
    "                    rnd.shuffle(lines_index)\n",
    "\n",
    "            # The current position is obtained using `lines_index[index]`\n",
    "            # Store the x value at the current position into the buffer_x\n",
    "            buffer_x[i] = x[lines_index[index]]\n",
    "\n",
    "            # Store the y value at the current position into the buffer_y\n",
    "            buffer_y[i] = y[lines_index[index]]\n",
    "\n",
    "            lenx = len(x[lines_index[index]])    #length of current x[]\n",
    "            if lenx > max_len:\n",
    "                max_len = lenx                   #max_len tracks longest x[]\n",
    "\n",
    "            # increment index by one\n",
    "            index += 1\n",
    "\n",
    "\n",
    "        # create X,Y, NumPy arrays of size (batch_size, max_len) 'full' of pad value\n",
    "        X = np.full((batch_size, max_len), pad)\n",
    "        Y = np.full((batch_size, max_len), pad)\n",
    "\n",
    "        # copy values from lists to NumPy arrays. Use the buffered values\n",
    "        for i in range(batch_size):\n",
    "            # get the example (sentence as a tensor)\n",
    "            # in `buffer_x` at the `i` index\n",
    "            x_i = buffer_x[i]\n",
    "\n",
    "            # similarly, get the example's labels\n",
    "            # in `buffer_y` at the `i` index\n",
    "            y_i = buffer_y[i]\n",
    "\n",
    "            # Walk through each word in x_i\n",
    "            for j in range(len(x_i)):\n",
    "                # store the word in x_i at position j into X\n",
    "                X[i, j] = x_i[j]\n",
    "\n",
    "                # store the label in y_i at position j into Y\n",
    "                Y[i, j] = y_i[j]\n",
    "\n",
    "        if verbose: print(\"index=\", index)\n",
    "        yield((X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729244813827,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "s3fwE3PMhOW4",
    "outputId": "21cdea7b-e879-4925-903a-7e1c964aa7bc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 5\n",
      "index= 2\n",
      "(5, 30) (5, 30) (5, 30) (5, 30)\n",
      "[    0     1     2     3     4     5     6     7     8     9    10    11\n",
      "    12    13    14     9    15     1    16    17    18    19    20    21\n",
      " 35180 35180 35180 35180 35180 35180] \n",
      " [    0     0     0     0     0     0     1     0     0     0     0     0\n",
      "     1     0     0     0     0     0     2     0     0     0     0     0\n",
      " 35180 35180 35180 35180 35180 35180]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "mini_sentences = t_sentences[0: 8]\n",
    "mini_labels = t_labels[0: 8]\n",
    "dg = data_generator(batch_size, mini_sentences, mini_labels, vocab[\"<PAD>\"], shuffle=False, verbose=True)\n",
    "X1, Y1 = next(dg)\n",
    "X2, Y2 = next(dg)\n",
    "print(Y1.shape, X1.shape, Y2.shape, X2.shape)\n",
    "print(X1[0][:], \"\\n\", Y1[0][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SWxKhkVLr3P"
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "# Part 2:  Building the model\n",
    "\n",
    "We will now implement the model. We will be using Google's TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1729244975734,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "vL5u72u8Lr3Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NER(vocab_size=35181, d_model=50, tags=tag_map):\n",
    "    '''\n",
    "      Input:\n",
    "        vocab_size - integer containing the size of the vocabulary\n",
    "        d_model - integer describing the embedding size\n",
    "      Output:\n",
    "        model - a trax serial model\n",
    "    '''\n",
    "    model = tl.Serial(\n",
    "      tl.Embedding(vocab_size, d_model), # Embedding layer\n",
    "      tl.LSTM(d_model), # LSTM layer\n",
    "      tl.Dense(len(tags)), # Dense layer with len(tags) units\n",
    "      tl.LogSoftmax()  # LogSoftmax layer\n",
    "      )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1729244980387,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "BrGdYpPvLr3U",
    "outputId": "18d4b453-3299-4f74-89b0-78524f98e330",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Embedding_35181_50\n",
      "  LSTM_50\n",
      "  Dense_17\n",
      "  LogSoftmax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# initializing your model\n",
    "model = NER()\n",
    "# display your model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LkjXxxhLr3Z"
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "# Part 3:  Train the Model\n",
    "\n",
    "This section will train our model.\n",
    "\n",
    "Before we start, we need to create the data generators for training and validation data. It is important that we mask padding in the loss weights of our data, which can be done using the `id_to_mask` argument of `trax.data.inputs.add_loss_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 963,
     "status": "ok",
     "timestamp": 1729244985535,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "C7B4Zk6T4J-B"
   },
   "outputs": [],
   "source": [
    "rnd.seed(33)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create training data, mask pad id=35180 for training.\n",
    "train_generator = trax.data.inputs.add_loss_weights(\n",
    "    data_generator(batch_size, t_sentences, t_labels, vocab['<PAD>'], True),\n",
    "    id_to_mask=vocab['<PAD>'])\n",
    "\n",
    "# Create validation data, mask pad id=35180 for training.\n",
    "eval_generator = trax.data.inputs.add_loss_weights(\n",
    "    data_generator(batch_size, v_sentences, v_labels, vocab['<PAD>'], True),\n",
    "    id_to_mask=vocab['<PAD>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SdkBrFVnCuV"
   },
   "source": [
    "<a name='3.1'></a>\n",
    "### 3.1 Training the model\n",
    "\n",
    "We will now write a function that takes in your model and trains it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729245021563,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "WV27PerULr3a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(NER, train_generator, eval_generator, train_steps=1, output_dir='model'):\n",
    "    '''\n",
    "    Input:\n",
    "        NER - the model you are building\n",
    "        train_generator - The data generator for training examples\n",
    "        eval_generator - The data generator for validation examples,\n",
    "        train_steps - number of training steps\n",
    "        output_dir - folder to save your model\n",
    "    Output:\n",
    "        training_loop - a trax supervised training Loop\n",
    "    '''\n",
    "    train_task = training.TrainTask(\n",
    "      train_generator, # A train data generator\n",
    "      loss_layer = tl.CrossEntropyLoss(), # A cross-entropy loss function\n",
    "      optimizer = trax.optimizers.Adam(0.01),  # The adam optimizer\n",
    "    )\n",
    "\n",
    "    eval_task = training.EvalTask(\n",
    "      labeled_data = eval_generator, # A labeled data generator\n",
    "      metrics = [tl.CrossEntropyLoss(), tl.Accuracy()], # Evaluate with cross-entropy loss and accuracy\n",
    "      n_eval_batches = 10  # Number of batches to use on each evaluation\n",
    "    )\n",
    "\n",
    "    training_loop = training.Loop(\n",
    "        NER, # A model to train\n",
    "        train_task, # A train task\n",
    "        eval_tasks=[eval_task],\n",
    "        output_dir = output_dir) # The output directory\n",
    "\n",
    "    # Train with train_steps\n",
    "    training_loop.run(n_steps = train_steps)\n",
    "\n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40825,
     "status": "ok",
     "timestamp": 1729245150008,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "VU-j8hs-nCue",
    "outputId": "a329ed9e-ab42-45ef-94dc-9b32203d6334"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py:1184: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/trax/layers/base.py:851: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip.GzipFile(fileobj=f, compresslevel=compresslevel) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 1780117\n",
      "Step      1: Ran 1 train steps in 2.50 secs\n",
      "Step      1: train CrossEntropyLoss |  4.04632664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trax/supervised/training.py:1249: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      1: eval  CrossEntropyLoss |  2.90042813\n",
      "Step      1: eval          Accuracy |  0.01860118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trax/layers/base.py:851: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip.GzipFile(fileobj=f, compresslevel=compresslevel) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step    100: Ran 99 train steps in 28.46 secs\n",
      "Step    100: train CrossEntropyLoss |  0.55899328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trax/supervised/training.py:1249: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    100: eval  CrossEntropyLoss |  0.25666570\n",
      "Step    100: eval          Accuracy |  0.93673508\n"
     ]
    }
   ],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "train_steps = 100\n",
    "!rm -f 'model/model.pkl.gz'  # Remove old model.pkl if it exists\n",
    "\n",
    "# Train the model\n",
    "training_loop = train_model(NER(), train_generator, eval_generator, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1271,
     "status": "ok",
     "timestamp": 1729245160830,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "ecIG67nenCui",
    "outputId": "5c59b008-fcf3-44af-b74d-78be1f7d79e0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[ 0.00626876, -0.1672094 ,  0.04730672, ...,  0.02100409,\n",
       "           0.09326503, -0.00318395],\n",
       "         [-0.26170006, -0.12213242, -0.18048875, ...,  0.11632765,\n",
       "           0.26826692, -0.00404759],\n",
       "         [-0.11117691, -0.26779622, -0.22080895, ..., -0.04907783,\n",
       "           0.18515159, -0.11594632],\n",
       "         ...,\n",
       "         [-0.19272566,  0.0865287 , -0.16018522, ...,  0.08917122,\n",
       "          -0.03077034, -0.0886739 ],\n",
       "         [-0.02528609,  0.11262495, -0.1404779 , ..., -0.06518547,\n",
       "          -0.07217853, -0.15837154],\n",
       "         [ 0.09185313, -0.01502389,  0.18619727, ...,  0.12835549,\n",
       "          -0.02299821,  0.02762324]], dtype=float32),\n",
       "  (((), ((), ())),\n",
       "   ((array([[ 0.23717202,  0.25847733,  0.14883976, ..., -0.4172051 ,\n",
       "              0.5753839 , -0.03026068],\n",
       "            [-0.17705357, -0.12066317, -0.01919067, ...,  0.42146364,\n",
       "              0.2907704 ,  0.40396497],\n",
       "            [-0.3361445 , -0.1928285 , -0.3859951 , ...,  0.3743336 ,\n",
       "             -0.42620894, -0.1325455 ],\n",
       "            ...,\n",
       "            [-0.10983678,  0.19601712,  0.0530295 , ..., -0.26456243,\n",
       "              0.26428515, -0.23991507],\n",
       "            [ 0.14742032,  0.01854263,  0.14212768, ..., -0.00486106,\n",
       "              0.08985127, -0.02295671],\n",
       "            [-0.03520492,  0.01405486, -0.00996084, ...,  0.03783666,\n",
       "              0.10338045, -0.05488039]], dtype=float32),\n",
       "     array([1.1984669 , 1.1287614 , 1.1471735 , 1.1305134 , 0.96805423,\n",
       "            1.1402396 , 1.0539232 , 0.9765151 , 1.1681447 , 1.0121598 ,\n",
       "            1.1416218 , 1.0308735 , 1.1990105 , 1.1855117 , 0.96423703,\n",
       "            0.90613514, 1.1653688 , 0.9300213 , 1.2162007 , 1.1202595 ,\n",
       "            0.961322  , 1.266214  , 1.258982  , 0.9097714 , 1.0611881 ,\n",
       "            0.9185843 , 0.9274884 , 1.1493843 , 1.020362  , 1.1279721 ,\n",
       "            1.1158612 , 1.0544467 , 1.1620872 , 0.93522745, 1.0784422 ,\n",
       "            1.1900331 , 0.94860166, 1.1496105 , 0.9354102 , 0.93442756,\n",
       "            0.9317553 , 0.89895916, 1.141283  , 1.1404474 , 0.98656756,\n",
       "            0.9458549 , 0.9865246 , 1.0159196 , 1.0970303 , 0.8806946 ,\n",
       "            1.1220815 , 1.0940706 , 1.1359766 , 1.1466248 , 0.8752821 ,\n",
       "            1.097007  , 1.0282565 , 0.87511843, 1.1523435 , 0.8565516 ,\n",
       "            1.101873  , 0.71026343, 1.221071  , 1.1443372 , 0.8483076 ,\n",
       "            0.88382196, 1.1638582 , 0.9045468 , 1.2591622 , 1.1268386 ,\n",
       "            0.8030799 , 1.2141769 , 1.1591364 , 0.85000515, 0.82926613,\n",
       "            0.8719946 , 0.86144304, 1.0895019 , 1.042353  , 1.0950639 ,\n",
       "            1.1095488 , 0.9916009 , 1.076836  , 0.8108448 , 0.79521674,\n",
       "            1.1519558 , 0.9264463 , 1.1669677 , 0.8840713 , 0.83127356,\n",
       "            0.9066463 , 0.89777595, 1.0925659 , 1.1658742 , 0.7007697 ,\n",
       "            0.71895945, 0.90148044, 0.85127187, 1.0196506 , 0.838818  ,\n",
       "            0.9160181 , 1.0940443 , 1.0728958 , 1.0896578 , 0.9142431 ,\n",
       "            1.06298   , 1.0559798 , 0.974074  , 1.0766444 , 0.92755663,\n",
       "            1.0697386 , 0.9959507 , 1.097246  , 1.0806835 , 0.9241513 ,\n",
       "            0.88225865, 1.091107  , 0.9126081 , 1.0935075 , 1.0797399 ,\n",
       "            0.926973  , 1.1234347 , 1.0648093 , 0.91029155, 0.8810083 ,\n",
       "            0.9442454 , 0.8542929 , 1.0861065 , 1.0122881 , 1.078665  ,\n",
       "            1.0787538 , 0.96132845, 0.9251143 , 0.8133757 , 0.97975796,\n",
       "            1.0708193 , 0.895692  , 1.0805851 , 0.90401125, 0.89261043,\n",
       "            0.965494  , 0.92362314, 1.0908892 , 1.0830027 , 0.93678623,\n",
       "            0.90480393, 0.8670067 , 0.9393745 , 1.0803485 , 0.86792976,\n",
       "            0.94110507, 1.0096474 , 1.055753  , 1.0081644 , 0.9454119 ,\n",
       "            1.044084  , 1.1010294 , 0.9786899 , 1.0565938 , 0.9835693 ,\n",
       "            0.8393559 , 1.0306591 , 1.098788  , 1.0293978 , 0.9615301 ,\n",
       "            0.9095709 , 1.0399159 , 0.9429364 , 1.0963689 , 1.0214173 ,\n",
       "            0.9708877 , 1.092933  , 0.9443536 , 0.92358315, 0.9725769 ,\n",
       "            0.94327694, 0.9292849 , 1.0142248 , 0.8908715 , 0.87165326,\n",
       "            0.9973363 , 0.9335626 , 0.8398671 , 0.9036011 , 1.0544962 ,\n",
       "            1.03122   , 0.9382371 , 1.0335855 , 0.9367702 , 0.931742  ,\n",
       "            0.9592103 , 0.9248692 , 1.0647726 , 1.0114524 , 0.986767  ,\n",
       "            0.955242  , 0.9462159 , 1.0122963 , 0.92732775, 0.88302416],\n",
       "           dtype=float32)),),\n",
       "   ()),\n",
       "  (array([[ 1.78656414e-01, -2.48842120e-01, -8.63798708e-02,\n",
       "            6.71297088e-02,  5.29095121e-02, -1.67478591e-01,\n",
       "           -1.14351455e-02, -3.66905749e-01,  8.45274255e-02,\n",
       "           -3.00662249e-01, -2.14365050e-01, -3.95578504e-01,\n",
       "           -2.26329282e-01, -1.70926049e-01, -1.18969053e-01,\n",
       "            2.24945042e-03,  1.32937906e-02],\n",
       "          [ 3.73650491e-01, -1.78102314e-01,  4.24188338e-02,\n",
       "            8.00543427e-02, -1.58936545e-01, -1.62800074e-01,\n",
       "            3.86485015e-03,  1.67677730e-01, -6.59777969e-02,\n",
       "            8.13098326e-02, -2.03705654e-02, -4.50019598e-01,\n",
       "            7.54629523e-02, -1.67457104e-01,  2.95753442e-02,\n",
       "            7.82282054e-02, -4.63317662e-01],\n",
       "          [ 3.32298219e-01,  2.55333185e-01, -3.56669396e-01,\n",
       "           -2.02661291e-01,  1.31085336e-01,  1.58757463e-01,\n",
       "           -1.26463085e-01, -3.60211194e-01, -3.26633602e-01,\n",
       "            1.21608421e-01,  1.31265908e-01, -2.16850266e-01,\n",
       "            2.25546002e-01, -1.43301025e-01, -3.15125763e-01,\n",
       "           -2.35334903e-01, -3.74231488e-02],\n",
       "          [ 3.80104095e-01, -6.94131106e-02, -3.64639193e-01,\n",
       "            1.05973125e-01,  1.00232679e-02, -1.46565884e-01,\n",
       "           -1.48670152e-02,  5.47495373e-02, -2.19075188e-01,\n",
       "           -6.49243146e-02, -1.01917416e-01,  7.42881596e-02,\n",
       "           -2.54056752e-01,  7.94663734e-04, -7.90985972e-02,\n",
       "           -3.38062137e-01, -1.27960071e-01],\n",
       "          [-5.85707277e-03, -4.67618108e-01, -6.21437371e-01,\n",
       "           -6.09449625e-01, -4.99116212e-01,  1.23322554e-01,\n",
       "            1.53889522e-01,  4.62450176e-01,  3.84219773e-02,\n",
       "            5.52841322e-03, -3.04823041e-01, -1.67780131e-01,\n",
       "            3.48743767e-01, -3.63959931e-02,  1.96760416e-01,\n",
       "           -2.53084213e-01,  3.95199507e-02],\n",
       "          [ 3.71136039e-01, -7.18025938e-02,  1.48560628e-02,\n",
       "           -2.78195798e-01, -8.90911371e-02,  2.25929841e-01,\n",
       "           -1.05675980e-01, -1.98448449e-01, -2.99934566e-01,\n",
       "           -4.02579874e-01, -2.95300663e-01, -6.88995868e-02,\n",
       "            6.11361414e-02, -4.03413415e-01, -1.18592441e-01,\n",
       "           -2.12856621e-01, -1.05487481e-01],\n",
       "          [ 8.25931057e-02, -4.14756536e-01, -3.72333340e-02,\n",
       "            6.54690862e-02, -1.12181697e-02, -4.15840179e-01,\n",
       "            2.34908283e-01, -4.46385235e-01, -2.04973176e-01,\n",
       "           -4.05254096e-01,  4.34516698e-01, -1.82313785e-01,\n",
       "            3.93151879e-01, -2.15206325e-01,  5.31285480e-02,\n",
       "            1.12446010e-01, -8.06729868e-02],\n",
       "          [-1.70395657e-01,  8.35200325e-02,  2.07180560e-01,\n",
       "           -2.46032677e-03, -7.24690035e-02,  1.03113323e-01,\n",
       "            1.71461567e-01, -1.86643809e-01, -2.72948325e-01,\n",
       "           -3.36752743e-01,  2.67773628e-01, -1.89463735e-01,\n",
       "            2.45794535e-01, -3.88636738e-01, -9.49157029e-02,\n",
       "           -3.03530514e-01,  1.12652304e-02],\n",
       "          [ 2.94992626e-01, -2.36716680e-02, -1.76463768e-01,\n",
       "            2.71149069e-01, -2.53018528e-01, -2.42971927e-01,\n",
       "            1.37007415e-01, -9.89632457e-02, -3.47035706e-01,\n",
       "           -1.88376725e-01, -2.96818197e-01, -2.74860114e-01,\n",
       "           -1.59105305e-02,  3.50563228e-02, -3.22592445e-02,\n",
       "           -4.65665877e-01, -3.58991057e-01],\n",
       "          [ 1.13406312e-02, -4.94549811e-01,  5.75726569e-01,\n",
       "            1.65272459e-01,  3.26230004e-02, -4.26767826e-01,\n",
       "            9.24084336e-02,  9.76584777e-02, -2.09007815e-01,\n",
       "           -3.44082624e-01,  3.43646348e-01,  2.66671535e-02,\n",
       "            1.51837282e-02, -2.40173727e-01, -2.55480021e-01,\n",
       "           -3.99598368e-02, -6.93225414e-02],\n",
       "          [ 4.06447100e-03,  1.68377683e-01, -2.41958767e-01,\n",
       "           -5.23366556e-02, -8.86379555e-02,  2.17703789e-01,\n",
       "           -2.36669257e-01, -7.99390376e-02, -3.51289719e-01,\n",
       "           -3.43928337e-01, -4.84405249e-01, -1.73070163e-01,\n",
       "           -8.67509469e-02, -1.21017426e-01, -4.28282470e-01,\n",
       "           -2.02800497e-01, -3.58903944e-01],\n",
       "          [ 5.09228706e-02, -3.51963192e-01, -4.50926363e-01,\n",
       "           -3.84034485e-01, -1.58888340e-01, -3.60253841e-01,\n",
       "           -3.53779465e-01, -3.16269457e-01, -2.57956117e-01,\n",
       "            1.26034319e-01, -4.06563073e-01, -2.79724952e-02,\n",
       "           -1.42949432e-01, -2.76604563e-01, -1.47305354e-01,\n",
       "           -7.38464668e-03,  1.16794519e-01],\n",
       "          [ 3.03906977e-01,  1.16982348e-01, -4.22982961e-01,\n",
       "            2.35358894e-01,  1.04011469e-01,  1.11567676e-01,\n",
       "            1.96920693e-01, -4.36161786e-01, -1.35226846e-02,\n",
       "           -2.56891698e-01,  2.61471480e-01,  1.25430465e-01,\n",
       "           -2.70045519e-01,  4.73028496e-02, -3.89828205e-01,\n",
       "           -5.31285927e-02, -2.48566523e-01],\n",
       "          [ 2.47506067e-01, -1.24987975e-01, -4.70169000e-02,\n",
       "            1.85090408e-01, -1.60642505e-01, -3.08247179e-01,\n",
       "            4.24511358e-02,  8.54675546e-02, -3.29086185e-01,\n",
       "           -4.44869012e-01,  3.22223804e-03, -7.16794431e-02,\n",
       "           -2.22764120e-01, -2.57446080e-01, -3.09778273e-01,\n",
       "           -1.85994253e-01, -3.83994393e-02],\n",
       "          [-5.24119399e-02,  4.57457572e-01,  1.51724011e-01,\n",
       "           -5.99420190e-01, -5.63483802e-04,  1.52708814e-01,\n",
       "            7.39793032e-02, -4.98558223e-01, -2.28050607e-03,\n",
       "           -2.68947154e-01, -8.69786263e-01, -1.34949818e-01,\n",
       "           -5.35307050e-01, -9.08158422e-02, -1.73253492e-01,\n",
       "            1.54232964e-01, -2.71290928e-01],\n",
       "          [-1.92155540e-01,  2.30571777e-01,  1.09476842e-01,\n",
       "           -3.46550822e-01, -1.67124063e-01, -1.83615610e-01,\n",
       "            2.39492785e-02,  1.73416391e-01, -1.28833875e-01,\n",
       "           -1.23281311e-02, -6.86672807e-01, -1.44557863e-01,\n",
       "            1.97641596e-01, -1.97529688e-01, -3.63917828e-01,\n",
       "           -1.33167267e-01, -3.21370579e-04],\n",
       "          [ 1.32580712e-01,  2.75867730e-01,  2.04699226e-02,\n",
       "            1.25296697e-01, -4.27621007e-01,  1.35019142e-02,\n",
       "           -7.41380453e-02,  2.49688163e-01, -1.11234263e-02,\n",
       "           -4.26569194e-01,  2.09566027e-01, -8.88954028e-02,\n",
       "           -8.06129128e-02, -3.70979637e-01, -5.45182407e-01,\n",
       "           -1.73025981e-01, -3.52755696e-01],\n",
       "          [-9.91108492e-02, -4.72610235e-01,  3.08288604e-01,\n",
       "            2.52491355e-01, -5.07596545e-02, -2.07530633e-02,\n",
       "            1.03622926e-02, -8.33398879e-01,  2.10015520e-01,\n",
       "            1.33774370e-01,  1.82439983e-01,  3.47029977e-02,\n",
       "           -4.09747273e-01,  4.43389937e-02, -2.67042309e-01,\n",
       "           -3.48274440e-01, -3.72219563e-01],\n",
       "          [ 1.98729068e-01, -1.75151348e-01, -1.62708551e-01,\n",
       "           -8.13216045e-02,  7.13784322e-02,  1.00049734e-01,\n",
       "            1.25050202e-01, -3.80913466e-01, -4.15151298e-01,\n",
       "           -2.21676767e-01, -2.46240664e-02, -1.67439237e-01,\n",
       "           -1.97641611e-01, -1.94744676e-01, -8.17858875e-02,\n",
       "           -3.43031883e-01, -4.04853195e-01],\n",
       "          [ 3.91593724e-01, -1.02735989e-01, -2.25214422e-01,\n",
       "           -1.29218578e-01, -3.28605443e-01, -3.20648670e-01,\n",
       "            4.43273708e-02, -6.08076639e-02, -2.80346066e-01,\n",
       "           -2.22812258e-02,  1.65049329e-01, -3.34489048e-01,\n",
       "           -2.06568196e-01, -1.81731597e-01, -3.75798762e-01,\n",
       "            8.39170292e-02, -3.98706039e-03],\n",
       "          [ 3.18170451e-02, -2.95078069e-01,  2.10117355e-01,\n",
       "            3.39262724e-01, -2.18983680e-01, -2.67504930e-01,\n",
       "           -4.61920910e-02,  1.61915049e-01,  7.52534270e-02,\n",
       "           -3.57012868e-01, -3.66053939e-01,  1.05825461e-01,\n",
       "           -4.02908832e-01, -3.11226159e-01,  3.13779265e-02,\n",
       "            1.44123361e-01,  1.30891308e-01],\n",
       "          [ 2.57926524e-01, -3.52788836e-01, -3.47431749e-01,\n",
       "           -3.81619900e-01, -1.94684714e-01,  2.06346199e-01,\n",
       "            2.38705590e-01,  4.83513288e-02, -1.73638761e-01,\n",
       "           -2.74659067e-01,  2.88608730e-01, -3.40607703e-01,\n",
       "           -9.01187584e-02, -4.59537804e-01, -2.81169474e-01,\n",
       "           -6.97812811e-02,  5.71300536e-02],\n",
       "          [ 6.94502667e-02, -5.61545044e-03,  4.06926513e-01,\n",
       "            4.54193115e-01,  2.47707948e-01,  3.75454038e-01,\n",
       "           -4.33684140e-02, -1.99207351e-01, -1.05253793e-01,\n",
       "           -4.48956072e-01,  1.22813247e-01, -4.14253771e-01,\n",
       "           -3.68729889e-01, -5.03686704e-02, -4.75209318e-02,\n",
       "           -1.23827279e-01, -6.67099878e-02],\n",
       "          [-3.90840741e-03, -7.38686472e-02,  2.89528966e-01,\n",
       "           -1.92117900e-01, -3.79658699e-01, -3.07985232e-03,\n",
       "            6.11334182e-02, -4.97682065e-01, -3.80434990e-02,\n",
       "           -8.70584920e-02, -2.02135190e-01, -6.41779043e-03,\n",
       "           -3.67834449e-01,  1.49399757e-01,  1.81187496e-01,\n",
       "           -3.28553975e-01, -1.46349473e-02],\n",
       "          [ 9.32521150e-02,  6.67328775e-01,  3.51157963e-01,\n",
       "            4.76258546e-01, -4.34531979e-02,  3.95833142e-02,\n",
       "           -1.51017727e-02, -6.47862971e-01,  1.50318071e-01,\n",
       "           -3.25578600e-02,  2.29551449e-01,  1.51457563e-01,\n",
       "           -2.62370944e-01, -3.28132480e-01, -1.64232373e-01,\n",
       "           -9.14426297e-02,  1.32839635e-01],\n",
       "          [-2.22416341e-01,  2.74137825e-01,  2.11711720e-01,\n",
       "            1.77443132e-01, -3.28502744e-01,  2.01072320e-01,\n",
       "           -2.47117057e-01, -1.50305420e-01,  1.90855771e-01,\n",
       "            1.01372346e-01, -1.42880321e-01, -3.35850507e-01,\n",
       "            3.69848758e-02, -9.37480852e-02, -1.99511647e-01,\n",
       "            2.13870287e-01,  4.37008068e-02],\n",
       "          [ 2.36544982e-02,  6.98187768e-01, -1.69721484e-01,\n",
       "           -2.88398921e-01, -2.02243850e-01, -5.57681322e-02,\n",
       "            8.48064050e-02,  1.46547332e-01,  4.04195786e-02,\n",
       "            5.12124300e-02,  9.38745067e-02, -1.38458669e-01,\n",
       "            3.11033309e-01, -1.41535506e-01, -1.52449340e-01,\n",
       "           -3.61506969e-01, -2.12990120e-01],\n",
       "          [ 1.43870577e-01, -3.57045978e-01, -3.23963687e-02,\n",
       "           -3.18328351e-01, -1.69045150e-01, -2.51515746e-01,\n",
       "            3.10360622e-02, -1.24301352e-02,  5.50845489e-02,\n",
       "            8.71887133e-02,  1.59020662e-01,  9.01307072e-03,\n",
       "            1.02482550e-01, -4.81475562e-01, -3.37191135e-01,\n",
       "           -3.56091559e-01, -2.61734098e-01],\n",
       "          [ 2.16134638e-01, -3.49298954e-01, -1.47464424e-01,\n",
       "           -3.78896475e-01, -3.82371038e-01, -2.33648449e-01,\n",
       "            1.80764377e-01,  7.55094811e-02, -2.20031306e-01,\n",
       "           -1.94977731e-01, -2.72170126e-01, -5.09860478e-02,\n",
       "            1.31641356e-02,  1.09995648e-01,  8.83435830e-02,\n",
       "           -9.94322821e-02, -3.38428169e-02],\n",
       "          [ 1.01094335e-01,  5.16311005e-02, -2.89844483e-01,\n",
       "           -5.45068793e-02, -3.54909420e-01,  3.87548506e-02,\n",
       "           -2.19619602e-01, -2.24184990e-01,  1.32682845e-01,\n",
       "           -2.39126742e-01, -2.37325266e-01,  8.19868147e-02,\n",
       "           -1.37584597e-01,  3.03553045e-02, -1.91972196e-01,\n",
       "           -3.66013080e-01, -2.02659499e-02],\n",
       "          [ 3.37097466e-01, -2.85428792e-01, -2.89430857e-01,\n",
       "           -8.31354037e-02, -1.99129775e-01,  1.79826841e-01,\n",
       "           -2.41814703e-01, -3.76812309e-01,  5.42112365e-02,\n",
       "           -1.80209890e-01,  2.65062135e-02,  2.15007495e-02,\n",
       "            1.23945549e-01, -9.02698711e-02, -3.15251321e-01,\n",
       "           -2.31022492e-01, -9.74581912e-02],\n",
       "          [-6.09363057e-02,  4.58031207e-01,  6.78705126e-02,\n",
       "            3.50366950e-01,  5.55474833e-02,  2.95561194e-01,\n",
       "            1.66711912e-01,  2.78632671e-01, -2.21523732e-01,\n",
       "           -2.24173829e-01, -9.82180089e-02, -2.76318669e-01,\n",
       "           -1.27908647e-01, -4.22230601e-01, -2.25672364e-01,\n",
       "           -4.48457271e-01, -3.49061191e-01],\n",
       "          [ 8.74296799e-02, -1.10630132e-02,  5.43951765e-02,\n",
       "           -3.58286388e-02,  2.29878932e-01,  8.79908577e-02,\n",
       "           -1.72460943e-01, -3.19673829e-02,  8.59610960e-02,\n",
       "           -2.75545746e-01,  4.65468019e-01, -1.42727122e-01,\n",
       "            5.47666736e-02, -2.78943539e-01, -4.44764435e-01,\n",
       "           -3.07330102e-01, -8.65628049e-02],\n",
       "          [-1.28417194e-01,  4.74733293e-01, -5.29830903e-02,\n",
       "            3.20391089e-01, -2.35141784e-01,  2.47829199e-01,\n",
       "           -9.09688100e-02, -1.22220106e-02, -2.06473902e-01,\n",
       "            8.25068951e-02, -3.72056782e-01, -6.77691773e-02,\n",
       "           -2.16527551e-01,  9.94728208e-02, -2.34441876e-01,\n",
       "           -4.19456720e-01,  3.12876478e-02],\n",
       "          [ 1.67802751e-01, -2.15225607e-01, -4.81416434e-01,\n",
       "           -3.16643387e-01, -2.46361077e-01,  1.01874312e-02,\n",
       "           -2.29275465e-01, -4.42239940e-01,  5.66875339e-02,\n",
       "           -9.50809196e-02, -2.21314967e-01,  1.61990032e-01,\n",
       "           -2.64625877e-01,  1.25236109e-01, -2.29725540e-01,\n",
       "           -2.16025189e-01,  6.70671314e-02],\n",
       "          [ 3.76699090e-01, -2.06267074e-01,  8.85435864e-02,\n",
       "           -1.30477220e-01,  1.47196040e-01,  1.20601781e-01,\n",
       "            1.04316413e-01,  1.84748113e-01,  1.06324136e-01,\n",
       "           -1.64331257e-01,  1.59308925e-01, -4.11673933e-01,\n",
       "            1.14462398e-01, -3.69296879e-01, -3.84934306e-01,\n",
       "           -2.42312804e-01, -1.93958785e-02],\n",
       "          [-1.35918647e-01, -1.37615263e-01,  2.55941600e-01,\n",
       "            2.38638550e-01,  1.55187368e-01,  1.59436524e-01,\n",
       "            1.80272534e-01, -6.10570788e-01, -4.23503727e-01,\n",
       "           -1.19824950e-02, -3.25665250e-02, -2.77714074e-01,\n",
       "            2.09685698e-01,  1.49984330e-01, -3.62543285e-01,\n",
       "           -2.05570638e-01, -2.89322101e-02],\n",
       "          [ 2.47209847e-01, -3.32592279e-01, -2.40593776e-01,\n",
       "            8.78714472e-02,  1.79870695e-01, -2.18421146e-01,\n",
       "           -7.90056959e-02, -1.67498350e-01, -2.82419175e-01,\n",
       "            1.92299057e-02, -1.68559477e-01, -1.89203411e-01,\n",
       "            4.67324145e-02, -4.21642452e-01, -4.68443155e-01,\n",
       "           -2.16038432e-02, -3.85763198e-01],\n",
       "          [-3.98139320e-02, -3.98047417e-01, -6.73661351e-01,\n",
       "            5.84115744e-01, -3.44751060e-01, -3.37260574e-01,\n",
       "            3.84653993e-02, -6.45617366e-01,  1.43778203e-02,\n",
       "            4.41024527e-02,  3.83343279e-01,  3.55769061e-02,\n",
       "           -2.47802526e-01,  2.09559351e-01, -2.74063468e-01,\n",
       "           -1.13158800e-01,  8.13484043e-02],\n",
       "          [ 5.99817233e-03, -1.41443148e-01,  1.31201856e-02,\n",
       "           -1.81733757e-01,  2.15373427e-01, -2.94728696e-01,\n",
       "            2.05491856e-01,  2.27491081e-01, -1.56047150e-01,\n",
       "           -3.34667452e-02, -9.29458320e-01,  5.91353364e-02,\n",
       "           -9.36205462e-02, -1.72303915e-01, -4.45436865e-01,\n",
       "           -3.58636290e-01, -7.21627772e-02],\n",
       "          [-2.53773302e-01,  3.26961875e-02,  3.65121901e-01,\n",
       "            3.17039847e-01, -8.56378824e-02,  1.03260145e-01,\n",
       "            4.08983193e-02,  2.03627571e-02, -2.18992680e-01,\n",
       "            9.84810963e-02,  5.06084025e-01, -5.45035452e-02,\n",
       "           -5.03235579e-01,  9.31907743e-02,  1.66736141e-01,\n",
       "            3.37875426e-01,  1.67071506e-01],\n",
       "          [-1.99241221e-01, -7.84211308e-02, -1.94907580e-02,\n",
       "            1.26801759e-01, -1.74823478e-01, -1.58006459e-01,\n",
       "            1.49026945e-01, -2.70774126e-01, -2.71774411e-01,\n",
       "            1.77278668e-01,  3.03076774e-01, -2.67108500e-01,\n",
       "           -2.68883675e-01,  1.48916766e-01,  1.58406973e-01,\n",
       "           -3.43641400e-01,  1.81078300e-01],\n",
       "          [ 2.97060043e-01, -3.08279675e-02,  2.54554510e-01,\n",
       "            1.76048428e-01, -7.92502984e-03,  2.11016491e-01,\n",
       "            1.95602939e-01, -3.37601490e-02, -1.64179862e-01,\n",
       "           -3.58592510e-01, -3.23179752e-01, -4.14436549e-01,\n",
       "           -3.02706420e-01, -2.51710832e-01, -6.59423042e-03,\n",
       "           -4.63084280e-01, -2.50878513e-01],\n",
       "          [ 2.77470738e-01,  7.37886503e-02,  1.96511015e-01,\n",
       "            3.71982753e-01,  5.13856560e-02,  1.57169670e-01,\n",
       "           -2.17382118e-01, -3.94993983e-02,  7.87811205e-02,\n",
       "           -3.91163640e-02,  6.35655597e-02, -2.36316800e-01,\n",
       "           -1.78363755e-01,  1.12331726e-01, -1.58622161e-01,\n",
       "            6.38505220e-02, -3.88969183e-01],\n",
       "          [ 6.42461702e-02,  6.25116527e-01, -1.40551075e-01,\n",
       "            3.22127968e-01, -3.23390186e-01, -3.12920779e-01,\n",
       "           -5.16678542e-02, -5.61115630e-02,  7.75846690e-02,\n",
       "           -5.10843694e-02, -9.94649157e-02,  8.53136852e-02,\n",
       "           -2.25390822e-01, -2.62884885e-01,  1.57620460e-01,\n",
       "           -1.21373072e-01, -6.89887255e-02],\n",
       "          [-8.33725929e-02,  2.63479263e-01,  5.32995224e-01,\n",
       "           -6.47292793e-01, -1.90979809e-01, -2.34803855e-01,\n",
       "           -1.84217647e-01,  8.70345980e-02, -3.03160012e-01,\n",
       "           -3.32940936e-01, -9.00274515e-01,  6.69244211e-03,\n",
       "            8.68022665e-02,  1.14644319e-01, -1.85502946e-01,\n",
       "            8.66517704e-03, -3.47683877e-01],\n",
       "          [-1.53719828e-01,  2.49862969e-01,  2.28235349e-01,\n",
       "           -7.27981627e-02, -8.35238099e-02,  2.06980959e-01,\n",
       "           -2.71168612e-02, -2.49785800e-02,  6.79623485e-02,\n",
       "           -3.16900343e-01,  4.25098419e-01, -1.24854580e-01,\n",
       "           -1.37355343e-01, -1.42427027e-01, -1.29051521e-01,\n",
       "           -3.82032543e-01,  9.74656716e-02],\n",
       "          [-6.70532212e-02, -4.61679548e-01,  1.48225635e-01,\n",
       "            3.55307162e-01,  4.28232253e-02, -1.76849850e-02,\n",
       "           -3.37810457e-01, -5.48741579e-01, -1.44568279e-01,\n",
       "           -2.57698834e-01,  5.42354047e-01, -1.64910436e-01,\n",
       "           -7.50333667e-02, -1.97192967e-01, -2.76470304e-01,\n",
       "           -3.95089164e-02, -1.62327319e-01],\n",
       "          [ 2.00612649e-01,  1.54818192e-01, -3.05466086e-01,\n",
       "           -2.80317098e-01, -2.17308849e-02, -3.19985747e-01,\n",
       "            5.06003061e-03, -1.22721910e-01, -1.16368704e-01,\n",
       "           -3.85894597e-01, -9.75653157e-02, -3.35229337e-01,\n",
       "           -2.75675297e-01, -1.04650371e-01, -1.56301364e-01,\n",
       "           -1.30364805e-01, -2.55360305e-01],\n",
       "          [-1.85056627e-01, -1.25277504e-01, -3.48276883e-01,\n",
       "           -3.50710265e-02,  1.78910986e-01,  6.45574406e-02,\n",
       "           -3.16590548e-01,  3.13131332e-01,  6.79019615e-02,\n",
       "            8.63255411e-02, -3.56031179e-01, -2.15235323e-01,\n",
       "            1.08302571e-01, -1.13731071e-01, -3.42956893e-02,\n",
       "            1.04082711e-01,  6.47841170e-02]], dtype=float32),\n",
       "   array([ 0.10617857, -0.03039436,  0.01526184,  0.13547024, -0.07269902,\n",
       "           0.00858529, -0.04078192, -0.08339308, -0.17704438, -0.21268557,\n",
       "          -0.14551957, -0.18353693, -0.07464059, -0.20108992, -0.25424263,\n",
       "          -0.2138139 , -0.16780648], dtype=float32)),\n",
       "  ()),\n",
       " ((), (((), ((), ())), ((), ()), ()), (), ()))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in a pretrained model..\n",
    "model = NER()\n",
    "model.init(trax.shapes.ShapeDtype((1, 1), dtype=np.int32))\n",
    "\n",
    "# Load the pretrained model\n",
    "model.init_from_file('model/model.pkl.gz', weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4r-gXOZLr3j"
   },
   "source": [
    "<a name=\"4\"></a>\n",
    "# Part 4:  Compute Accuracy\n",
    "\n",
    "We will now evaluate in the test set. Previously, we have seen the accuracy on the training set and the validation (noted as eval) set. We will now evaluate on our test set. To get a good evaluation, we will need to create a mask to avoid counting the padding tokens when computing the accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmIvd_GXnCuk"
   },
   "source": [
    "\n",
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>More Detailed Instructions </b></font>\n",
    "</summary>\n",
    "\n",
    "* *Step 1*: model(sentences) will give you the predicted output.\n",
    "\n",
    "* *Step 2*: Prediction will produce an output with an added dimension. For each sentence, for each word, there will be a vector of probabilities for each tag type. For each sentence,word, you need to pick the maximum valued tag. This will require `np.argmax` and careful use of the `axis` argument.\n",
    "* *Step 3*: Create a mask to prevent counting pad characters. It has the same dimension as output. An example below on matrix comparison provides a hint.\n",
    "* *Step 4*: Compute the accuracy metric by comparing your outputs against your test labels. Take the sum of that and divide by the total number of **unpadded** tokens. Use your mask value to mask the padded tokens. Return the accuracy.\n",
    "</detail>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 942,
     "status": "ok",
     "timestamp": 1729245169990,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "3H0Kx1rnnCun",
    "outputId": "f119f712-fd5f-4c7a-a16c-72bed8282fcb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shapes (7194, 70) (7194, 70)\n"
     ]
    }
   ],
   "source": [
    "# create the evaluation inputs\n",
    "x, y = next(data_generator(len(test_sentences), test_sentences, test_labels, vocab['<PAD>']))\n",
    "print(\"input shapes\", x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2778,
     "status": "ok",
     "timestamp": 1729245174830,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "rh16zSTonCuq",
    "outputId": "d40620ad-0357-4a19-a9c3-12917b0ffddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "tmp_pred has shape: (7194, 70, 17)\n"
     ]
    }
   ],
   "source": [
    "# sample prediction\n",
    "tmp_pred = model(x)\n",
    "print(type(tmp_pred))\n",
    "print(f\"tmp_pred has shape: {tmp_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78l5MTSBnCut"
   },
   "source": [
    "Note that the model's prediction has 3 axes:\n",
    "- the number of examples\n",
    "- the number of words in each example (padded to be as long as the longest sentence in the batch)\n",
    "- the number of possible targets (the 17 named entity tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 1122,
     "status": "ok",
     "timestamp": 1729245181773,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "8ek59ro9nCut"
   },
   "outputs": [],
   "source": [
    "def evaluate_prediction(pred, labels, pad):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        pred: prediction array with shape\n",
    "            (num examples, max sentence length in batch, num of classes)\n",
    "        labels: array of size (batch_size, seq_len)\n",
    "        pad: integer representing pad character\n",
    "    Outputs:\n",
    "        accuracy: float\n",
    "    \"\"\"\n",
    "\n",
    "## step 1 ##\n",
    "    outputs = np.argmax(pred, axis=2)\n",
    "    print(\"outputs shape:\", outputs.shape)\n",
    "\n",
    "## step 2 ##\n",
    "    mask = labels != pad\n",
    "    print(\"mask shape:\", mask.shape, \"mask[0][20:30]:\", mask[0][20:30])\n",
    "## step 3 ##\n",
    "    accuracy = np.sum(outputs == labels) / float(np.sum(mask))\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1041,
     "status": "ok",
     "timestamp": 1729245187628,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "yCWFwt3m1sgL",
    "outputId": "b1b011ce-433a-471f-f434-24c0deeb1b53",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: (7194, 70)\n",
      "mask shape: (7194, 70) mask[0][20:30]: [ True  True  True False False False False False False False]\n",
      "accuracy:  0.93521255\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_prediction(model(x), y, vocab['<PAD>'])\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2FEleAFLr3r"
   },
   "source": [
    "<a name=\"5\"></a>\n",
    "# Part 5:  Testing with your own sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOeTPAx_Lr3t"
   },
   "source": [
    "Below, we can test it out with our own sentence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 943,
     "status": "ok",
     "timestamp": 1729245193568,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "0K4SyB20cHRf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is the function you will be using to test your own sentence.\n",
    "def predict(sentence, model, vocab, tag_map):\n",
    "    s = [vocab[token] if token in vocab else vocab['UNK'] for token in sentence.split(' ')]\n",
    "    batch_data = np.ones((1, len(s)))\n",
    "    batch_data[0][:] = s\n",
    "    sentence = np.array(batch_data).astype(int)\n",
    "    output = model(sentence)\n",
    "    outputs = np.argmax(output, axis=2)\n",
    "    labels = list(tag_map.keys())\n",
    "    pred = []\n",
    "    for i in range(len(outputs[0])):\n",
    "        idx = outputs[0][i]\n",
    "        pred_label = labels[idx]\n",
    "        pred.append(pred_label)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1729245200620,
     "user": {
      "displayName": "ines slimene",
      "userId": "14768879695822285756"
     },
     "user_tz": -60
    },
    "id": "vLZCHoiULr3u",
    "outputId": "a24b84bb-2447-4745-c271-1e16d7e825aa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter B-per\n",
      "White B-org\n",
      "House I-org\n",
      "Sunday B-tim\n",
      "morning I-tim\n",
      "White B-org\n",
      "House I-org\n"
     ]
    }
   ],
   "source": [
    "# Try the output for the introduction example\n",
    "#sentence = \"Many French citizens are goin to visit Morocco for summer\"\n",
    "#sentence = \"Sharon Floyd flew to Miami last Friday\"\n",
    "\n",
    "# New york times news:\n",
    "sentence = \"Peter Navarro, the White House director of trade and manufacturing policy of U.S, said in an interview on Sunday morning that the White House was working to prepare for the possibility of a second wave of the coronavirus in the fall, though he said it wouldn’t necessarily come\"\n",
    "s = [vocab[token] if token in vocab else vocab['UNK'] for token in sentence.split(' ')]\n",
    "predictions = predict(sentence, model, vocab, tag_map)\n",
    "for x,y in zip(sentence.split(' '), predictions):\n",
    "    if y != 'O':\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PD775_EtnTr"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "NLPC3-3A"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
