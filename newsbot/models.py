"""SQLAlchemy ORM models for the Newsbot data layer.

This module centralises database schema definitions so that both the
application runtime and auxiliary tooling (migrations, analytics jobs)
can share a consistent view of the database.  The schema mirrors the
previous SQLite layout while extending it with the production-oriented
``full_content_status`` column required for enrichment tracking.
"""
from __future__ import annotations

import enum
from datetime import datetime

from sqlalchemy import (
    Column,
    DateTime,
    Enum,
    ForeignKey,
    Integer,
    String,
    Text,
    UniqueConstraint,
)
from sqlalchemy.orm import declarative_base, relationship

Base = declarative_base()


class FullContentStatus(str, enum.Enum):
    """Enumeration of the enrichment outcomes for full article fetching."""

    SUCCESS = "success"
    TIMEOUT = "timeout"
    PAYWALL = "paywall"
    PARSE_ERROR = "parse_error"


class Article(Base):
    """Primary storage model for collected news articles."""

    __tablename__ = "articles"
    __table_args__ = (UniqueConstraint("link", name="uq_articles_link"),)

    id: int = Column(Integer, primary_key=True, autoincrement=True)
    title: str = Column(String(1024), nullable=False)
    link: str = Column(String(2048), nullable=False)
    publish_date: str | None = Column(String(128), nullable=True)
    source: str | None = Column(String(255), nullable=True)
    category: str | None = Column(String(128), nullable=True)
    content: str | None = Column(Text, nullable=True)
    full_content: str | None = Column(Text, nullable=True)
    full_content_status: FullContentStatus | None = Column(
        Enum(FullContentStatus, name="full_content_status", create_constraint=True),
        nullable=True,
    )
    created_at: datetime = Column(
        DateTime(timezone=True),
        default=datetime.utcnow,
        nullable=False,
    )
    updated_at: datetime = Column(
        DateTime(timezone=True),
        default=datetime.utcnow,
        onupdate=datetime.utcnow,
        nullable=False,
    )

    processed_article = relationship(
        "ProcessedArticle",
        uselist=False,
        back_populates="article",
        cascade="all, delete-orphan",
    )

    def __repr__(self) -> str:  # pragma: no cover - debug helper
        return f"<Article id={self.id} link={self.link!r}>"


class ProcessedArticle(Base):
    """Derived NLP artefacts generated by the Spark pipeline."""

    __tablename__ = "processed_articles"

    article_id: int = Column(
        Integer,
        ForeignKey("articles.id", ondelete="CASCADE"),
        primary_key=True,
    )
    token_count: int = Column(Integer, nullable=False)
    tokens: str = Column(Text, nullable=False)
    feature_vector: str = Column(Text, nullable=False)
    pipeline_version: str = Column(String(128), nullable=False)
    processed_at: datetime = Column(
        DateTime(timezone=True),
        default=datetime.utcnow,
        nullable=False,
    )

    article = relationship("Article", back_populates="processed_article")

    def __repr__(self) -> str:  # pragma: no cover - debug helper
        return f"<ProcessedArticle article_id={self.article_id}>"


__all__ = ["Base", "Article", "ProcessedArticle", "FullContentStatus"]
